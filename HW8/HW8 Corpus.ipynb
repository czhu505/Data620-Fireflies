{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data620 HW8  Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 3 : Fireflies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members: Chunhui Zhu, Yuen Chun Wong, Chunmei Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's assignment, you are asked to analyze high frequency words.\n",
    "\n",
    "Please answer the fo llowing questions in an Jupyter Notebook, posted to GitHub.\n",
    "\n",
    "Choose a corpus of interest.\n",
    "\n",
    "How many total unique words are in the corpus?  (Please feel free to define unique words in any interesting, defensible way).\n",
    "\n",
    "\n",
    "Taking the most common words, how many unique words represent half of the total words in the corpus?Identify the 200 highest frequency words in this corpus.\n",
    "\n",
    "\n",
    "Create a graph that shows the relative frequency of these 200 words.\n",
    "\n",
    "\n",
    "Does the observed relative frequency of these words follow Zipf’s law? Explain.\n",
    "\n",
    "\n",
    "In what ways do you think the frequency of the words in this corpus differ from “all words in all corpora.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a corpus of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#corpora is a large bodies of text data. Many corpora are designed to contain a careful balance of material in one or more genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\czhu5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file identifiers in this corpus\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar=nltk.corpus.gutenberg.words( 'shakespeare-caesar.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25833"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\czhu5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', 'by', 'William', 'Shakespeare', '1599', ']'], ['Actus', 'Primus', '.'], ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "#  Attempted to load tokenizers/punkt/english.pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "caesar_sentences=gutenberg.sents('shakespeare-caesar.txt')\n",
    "caesar_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['But', 'what', 'compact', 'meane', 'you', 'to', 'haue', 'with', 'vs', '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caesar_sentences[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_len=max([len(s) for s in caesar_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ouer',\n",
       "  'thy',\n",
       "  'wounds',\n",
       "  ',',\n",
       "  'now',\n",
       "  'do',\n",
       "  'I',\n",
       "  'Prophesie',\n",
       "  ',',\n",
       "  '(',\n",
       "  'Which',\n",
       "  'like',\n",
       "  'dumbe',\n",
       "  'mouthes',\n",
       "  'do',\n",
       "  'ope',\n",
       "  'their',\n",
       "  'Ruby',\n",
       "  'lips',\n",
       "  ',',\n",
       "  'To',\n",
       "  'begge',\n",
       "  'the',\n",
       "  'voyce',\n",
       "  'and',\n",
       "  'vtterance',\n",
       "  'of',\n",
       "  'my',\n",
       "  'Tongue',\n",
       "  ')',\n",
       "  'A',\n",
       "  'Curse',\n",
       "  'shall',\n",
       "  'light',\n",
       "  'vpon',\n",
       "  'the',\n",
       "  'limbes',\n",
       "  'of',\n",
       "  'men',\n",
       "  ';',\n",
       "  'Domesticke',\n",
       "  'Fury',\n",
       "  ',',\n",
       "  'and',\n",
       "  'fierce',\n",
       "  'Ciuill',\n",
       "  'strife',\n",
       "  ',',\n",
       "  'Shall',\n",
       "  'cumber',\n",
       "  'all',\n",
       "  'the',\n",
       "  'parts',\n",
       "  'of',\n",
       "  'Italy',\n",
       "  ':',\n",
       "  'Blood',\n",
       "  'and',\n",
       "  'destruction',\n",
       "  'shall',\n",
       "  'be',\n",
       "  'so',\n",
       "  'in',\n",
       "  'vse',\n",
       "  ',',\n",
       "  'And',\n",
       "  'dreadfull',\n",
       "  'Obiects',\n",
       "  'so',\n",
       "  'familiar',\n",
       "  ',',\n",
       "  'That',\n",
       "  'Mothers',\n",
       "  'shall',\n",
       "  'but',\n",
       "  'smile',\n",
       "  ',',\n",
       "  'when',\n",
       "  'they',\n",
       "  'behold',\n",
       "  'Their',\n",
       "  'Infants',\n",
       "  'quartered',\n",
       "  'with',\n",
       "  'the',\n",
       "  'hands',\n",
       "  'of',\n",
       "  'Warre',\n",
       "  ':',\n",
       "  'All',\n",
       "  'pitty',\n",
       "  'choak',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'with',\n",
       "  'custome',\n",
       "  'of',\n",
       "  'fell',\n",
       "  'deeds',\n",
       "  ',',\n",
       "  'And',\n",
       "  'Caesars',\n",
       "  'Spirit',\n",
       "  'ranging',\n",
       "  'for',\n",
       "  'Reuenge',\n",
       "  ',',\n",
       "  'With',\n",
       "  'Ate',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  ',',\n",
       "  'come',\n",
       "  'hot',\n",
       "  'from',\n",
       "  'Hell',\n",
       "  ',',\n",
       "  'Shall',\n",
       "  'in',\n",
       "  'these',\n",
       "  'Confines',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'Monarkes',\n",
       "  'voyce',\n",
       "  ',',\n",
       "  'Cry',\n",
       "  'hauocke',\n",
       "  ',',\n",
       "  'and',\n",
       "  'let',\n",
       "  'slip',\n",
       "  'the',\n",
       "  'Dogges',\n",
       "  'of',\n",
       "  'Warre',\n",
       "  ',',\n",
       "  'That',\n",
       "  'this',\n",
       "  'foule',\n",
       "  'deede',\n",
       "  ',',\n",
       "  'shall',\n",
       "  'smell',\n",
       "  'aboue',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'With',\n",
       "  'Carrion',\n",
       "  'men',\n",
       "  ',',\n",
       "  'groaning',\n",
       "  'for',\n",
       "  'Buriall',\n",
       "  '.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in caesar_sentences if len(s)== longest_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many total unique words are in the corpus? (Please feel free to define unique words in any interesting, defensible way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-70f2a553ff45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmy_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mWords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmy_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaesar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Words' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "my_counter = Counter()\n",
    "for word in Words:\n",
    "    my_counter.update(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the most common words, how many unique words represent half of the total words in the corpus?Identify the 200 highest frequency words in this corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
